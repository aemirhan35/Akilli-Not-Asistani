import os
import torch
from pyannote.audio import Pipeline
from faster_whisper import WhisperModel
import numpy as np

# import os
HF_TOKEN = os.getenv("HF_TOKEN")

# Ses dosyasÄ± yolu
AUDIO_FILE = "backend/sample/ses_dosyasi.ogg"

# Whisper Model Boyutu (tiny, base, small, medium, large-v2)
MODEL_SIZE = "medium"  # Ä°yi sonuÃ§ iÃ§in medium veya large Ã¶neririm

def main():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"--- Sistem: {device} kullanÄ±lÄ±yor ---")

    # 1. WHISPER Ä°LE YAZIYA DÃ–KME (TRANSCRIPTION)
    print("\n1. Whisper Ã§alÄ±ÅŸÄ±yor (Metin Ã§Ä±karÄ±lÄ±yor)...")
    try:
        # compute_type="float16" GPU iÃ§in, hata verirse "int8" yap
        model = WhisperModel(MODEL_SIZE, device=device, compute_type="float16")
    except:
        print("GPU float16 desteklemiyor olabilir, int8 deneniyor...")
        model = WhisperModel(MODEL_SIZE, device=device, compute_type="int8")

    segments, info = model.transcribe(AUDIO_FILE, beam_size=5, language="tr")
    
    # Whisper segmentlerini listeye Ã§evirelim (Ã§Ã¼nkÃ¼ generator dÃ¶nÃ¼yor)
    whisper_segments = list(segments)
    print(f"   -> Toplam {len(whisper_segments)} cÃ¼mle bulundu.")

    # 2. PYANNOTE Ä°LE KONUÅMACI AYRIMI (DIARIZATION)
    print("\n2. Pyannote Ã§alÄ±ÅŸÄ±yor (KonuÅŸmacÄ±lar ayrÄ±lÄ±yor)...")
    try:
        pipeline = Pipeline.from_pretrained(
            "pyannote/speaker-diarization-3.0",
            use_auth_token=HF_TOKEN
        ).to(torch.device(device))
        
        diarization = pipeline(AUDIO_FILE)
    except Exception as e:
        print(f"HATA: Pyannote Ã§alÄ±ÅŸtÄ±rÄ±lamadÄ±. {e}")
        return

    # 3. BÄ°RLEÅTÄ°RME (MAPPING)
    print("\n3. Metin ve KonuÅŸmacÄ±lar eÅŸleÅŸtiriliyor...\n")
    print("-" * 50)
    
    # Pyannote sonuÃ§larÄ±nÄ± iÅŸlenebilir hale getir
    diarization_list = list(diarization.itertracks(yield_label=True))

    for segment in whisper_segments:
        start_time = segment.start
        end_time = segment.end
        text = segment.text

        # Bu cÃ¼mle aralÄ±ÄŸÄ±nda (start-end) en Ã§ok kim konuÅŸtu?
        # Basit bir sayaÃ§ mantÄ±ÄŸÄ±:
        speakers_counter = {}
        
        for turn, _, speaker in diarization_list:
            # KesiÅŸim var mÄ±?
            # turn.start ile turn.end aralÄ±ÄŸÄ±, bizim cÃ¼mle aralÄ±ÄŸÄ±na giriyor mu?
            intersection_start = max(start_time, turn.start)
            intersection_end = min(end_time, turn.end)
            
            if intersection_end > intersection_start:
                duration = intersection_end - intersection_start
                if speaker in speakers_counter:
                    speakers_counter[speaker] += duration
                else:
                    speakers_counter[speaker] = duration

        # En baskÄ±n konuÅŸmacÄ±yÄ± bul
        if speakers_counter:
            best_speaker = max(speakers_counter, key=speakers_counter.get)
        else:
            best_speaker = "Bilinmiyor"

        # SONUCU YAZDIR
        print(f"[{start_time:.1f}s - {end_time:.1f}s] {best_speaker}: {text}")

    print("-" * 50)
    print("Ä°ÅŸlem TamamlandÄ±! ğŸš€")

if __name__ == "__main__":
    main()